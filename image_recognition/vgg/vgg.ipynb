{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- VGG 구현 및 정리: https://blogofth-lee.tistory.com/264\n",
    "- VGGNet으로 ImageNet학습하기: https://minjoos.tistory.com/6\n",
    "- VGGnet(2014) 구현하기: https://deep-learning-study.tistory.com/521\n",
    "- VGGNet 논문 리뷰와 구현: https://wolfy.tistory.com/240\n",
    "- VGG16 Transfer Learning - Kaggle: https://www.kaggle.com/code/carloalbertobarbano/vgg16-transfer-learning-pytorch/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import package\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "from torchsummary import summary \n",
    "from torch import optim \n",
    "from torch.optim.lr_scheduler import StepLR \n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms \n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import utils\n",
    "import matplotlib.pyplot as plt \n",
    "plt.ion()   # 대화형 모드\n",
    "\n",
    "import numpy as np\n",
    "import os, time, copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# specify a data path\n",
    "path2data = '../data/STL10'\n",
    "\n",
    "# if not exists the path, make the directory\n",
    "if not os.path.exists(path2data):\n",
    "    os.mkdir(path2data)\n",
    "\n",
    "# load dataset\n",
    "train_ds = datasets.STL10(path2data, split='train', download=True, transform=transforms.ToTensor())\n",
    "val_ds = datasets.STL10(path2data, split='test', download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 96, 96])\n",
      "5000\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "# check train_ds\n",
    "img, _ = train_ds[1]\n",
    "print(img.shape)\n",
    "\n",
    "print(len(train_ds))\n",
    "print(len(val_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 구축\n",
    "> VGGnet은 4가지 종류가 있습니다. 각 종류에 해당하는 정보를 딕셔너리로 만듭니다. 숫자는 conv layer를 거친 후에 출력값 채널을 의미합니다. M은 pooling layer를 의미합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_types = {\n",
    "  'VGG11': [\n",
    "    64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'\n",
    "  ],\n",
    "  'VGG13': [\n",
    "    64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512\n",
    "  ],\n",
    "  'VGG16': [\n",
    "    64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'\n",
    "  ],\n",
    "  'VGG19': [\n",
    "    64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define VGGNet class\n",
    "class VGGnet(nn.Module):\n",
    "  # define a function to create conv layer taken the key of VGG type dict\n",
    "  def create_conv_laters(self, architecture):\n",
    "    layers = []\n",
    "    in_channels = self.in_channels\n",
    "    for x in architecture:\n",
    "      if isinstance(x, int): # int means conv layer\n",
    "        out_channels = x\n",
    "        layers += [\n",
    "          nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=(3,3), stride=(1,1), padding=(1,1)),\n",
    "          nn.BatchNorm2d(x),\n",
    "          nn.ReLU()\n",
    "        ]\n",
    "        in_channels = x\n",
    "      elif x == 'M':\n",
    "        layers += [\n",
    "          nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "        ]\n",
    "    \n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "  def _initialize_weights(self):\n",
    "    for m in self.modules():\n",
    "      if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "          nn.init.constant_(m.bias, 0)\n",
    "      elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "      elif isinstance(m, nn.Linear):\n",
    "        nn.init.normal_(m.weight, 0, 0.01)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "  \n",
    "  def __init__(self, model, in_channels=3, num_classes=10, init_weights=True):\n",
    "    super().__init__()\n",
    "    self.in_channels = in_channels\n",
    "\n",
    "    # create conv layers corresponding to VGG type \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "819822aad1d7dd5a8911f6442f86af1dcc8bcd014a1dc82c30af569169ee7dac"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('pytorch3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
