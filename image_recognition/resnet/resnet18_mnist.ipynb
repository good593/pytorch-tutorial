{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://github.com/ndb796/Deep-Learning-Paper-Review-and-Practice/blob/master/code_practices/ResNet18_MNIST_Train.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet18 모델 정의 및 인스턴스 초기화\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torch.backends.cudnn as cudnn \n",
    "import torch.optim as optim \n",
    "import os \n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet18을 위해 최대한 간단히 수정한 BasicBlock 클래스 정의 \n",
    "class BasicBlock(nn.Module):\n",
    "  def __init__(self, in_planes, planes, stride=1):\n",
    "    super(BasicBlock, self).__init__()\n",
    "\n",
    "    # 3x3 필터를 사용(너비와 높이를 줄일 때는 stride 값 조절)\n",
    "    self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "    self.bn1 = nn.BatchNorm2d(planes) # 배치 정규화(Batch normalization)\n",
    "\n",
    "    # 3x3 필터를 사용(패딩을 1만큼 주기 때문에 너비와 높이가 동일)\n",
    "    self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    self.bn2 = nn.BatchNorm2d(planes) # 배치 정규화(Batch normalization)\n",
    "\n",
    "    self.shortcut = nn.Sequential() # identity인 경우\n",
    "    if stride != 1: # stride가 1이 아니라면, Identity mapping이 아닌 경우\n",
    "      self.shortcut = nn.Sequential(\n",
    "        nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "        nn.BatchNorm2d(planes)\n",
    "      )\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = F.relu(self.bn1(self.conv1(x)))\n",
    "    out = self.bn2(self.conv2(out))\n",
    "    out += self.shortcut(x) # (핵심) skip connection\n",
    "    out = F.relu(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet 클래스 정의\n",
    "class ResNet(nn.Module):\n",
    "  def _make_layer(self, block, planes, num_blocks, stride):\n",
    "    strides = [stride] + [1] * (num_blocks -1)\n",
    "    layers = []\n",
    "\n",
    "    for _stride in strides:\n",
    "      layers.append(block(self.in_planes, planes, _stride))\n",
    "      self.in_planes = planes # 다음 레이어를 위해 채널 수 변경\n",
    "    \n",
    "    return nn.Sequential(*layers)\n",
    "  \n",
    "  def __init__(self, block, num_blocks, num_classes=10):\n",
    "    super(ResNet, self).__init__()\n",
    "    self.in_planes = 64\n",
    "\n",
    "    # 64개의 3x3 필터(filter)를 사용\n",
    "    self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    self.bn1 = nn.BatchNorm2d(64)\n",
    "    self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "    self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "    self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "    self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "    self.linear = nn.Linear(512, num_classes)\n",
    "\n",
    "  def forward(self, x):\n",
    "    print(f'x: {x.size()}')\n",
    "    out = F.relu(self.bn1(self.conv1(x)))\n",
    "    out = self.layer1(out)\n",
    "    out = self.layer2(out)\n",
    "    out = self.layer3(out)\n",
    "    out = self.layer4(out)\n",
    "    out = F.avg_pool2d(out, 4)\n",
    "    out = out.view(out.size(0), -1)\n",
    "    print(f'out: {out.size()}')\n",
    "    out = self.linear(out)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet 18 함수 정의\n",
    "def ResNet18():\n",
    "  return ResNet(BasicBlock, [2, 2, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([128, 1, 28, 28])\n",
      "out: torch.Size([128, 512])\n",
      "torch.Size([128, 10])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\n",
    "  'cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "model = ResNet18().to(device)\n",
    "x = torch.randn(128, 1, 28, 28).to(device)\n",
    "output = model(x)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([2, 1, 28, 28])\n",
      "out: torch.Size([2, 512])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 28, 28]             576\n",
      "       BatchNorm2d-2           [-1, 64, 28, 28]             128\n",
      "            Conv2d-3           [-1, 64, 28, 28]          36,864\n",
      "       BatchNorm2d-4           [-1, 64, 28, 28]             128\n",
      "            Conv2d-5           [-1, 64, 28, 28]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 28, 28]             128\n",
      "        BasicBlock-7           [-1, 64, 28, 28]               0\n",
      "            Conv2d-8           [-1, 64, 28, 28]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 28, 28]             128\n",
      "           Conv2d-10           [-1, 64, 28, 28]          36,864\n",
      "      BatchNorm2d-11           [-1, 64, 28, 28]             128\n",
      "       BasicBlock-12           [-1, 64, 28, 28]               0\n",
      "           Conv2d-13          [-1, 128, 14, 14]          73,728\n",
      "      BatchNorm2d-14          [-1, 128, 14, 14]             256\n",
      "           Conv2d-15          [-1, 128, 14, 14]         147,456\n",
      "      BatchNorm2d-16          [-1, 128, 14, 14]             256\n",
      "           Conv2d-17          [-1, 128, 14, 14]           8,192\n",
      "      BatchNorm2d-18          [-1, 128, 14, 14]             256\n",
      "       BasicBlock-19          [-1, 128, 14, 14]               0\n",
      "           Conv2d-20          [-1, 128, 14, 14]         147,456\n",
      "      BatchNorm2d-21          [-1, 128, 14, 14]             256\n",
      "           Conv2d-22          [-1, 128, 14, 14]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 14, 14]             256\n",
      "       BasicBlock-24          [-1, 128, 14, 14]               0\n",
      "           Conv2d-25            [-1, 256, 7, 7]         294,912\n",
      "      BatchNorm2d-26            [-1, 256, 7, 7]             512\n",
      "           Conv2d-27            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-28            [-1, 256, 7, 7]             512\n",
      "           Conv2d-29            [-1, 256, 7, 7]          32,768\n",
      "      BatchNorm2d-30            [-1, 256, 7, 7]             512\n",
      "       BasicBlock-31            [-1, 256, 7, 7]               0\n",
      "           Conv2d-32            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-33            [-1, 256, 7, 7]             512\n",
      "           Conv2d-34            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-35            [-1, 256, 7, 7]             512\n",
      "       BasicBlock-36            [-1, 256, 7, 7]               0\n",
      "           Conv2d-37            [-1, 512, 4, 4]       1,179,648\n",
      "      BatchNorm2d-38            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-39            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-40            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-41            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-42            [-1, 512, 4, 4]           1,024\n",
      "       BasicBlock-43            [-1, 512, 4, 4]               0\n",
      "           Conv2d-44            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-45            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-46            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-47            [-1, 512, 4, 4]           1,024\n",
      "       BasicBlock-48            [-1, 512, 4, 4]               0\n",
      "           Linear-49                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 11,172,810\n",
      "Trainable params: 11,172,810\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 8.79\n",
      "Params size (MB): 42.62\n",
      "Estimated Total Size (MB): 51.41\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (1, 28, 28), device=device.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 다운로드 및 불러오기\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms \n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "  transforms.ToTensor()\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "  transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='../../data', train=True, download=True, transform=transform_train)\n",
    "test_dataset = torchvision.datasets.MNIST(root='../../data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경 설정 및 학습 함수 정의\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = ResNet18()\n",
    "net = net.to(device)\n",
    "net = torch.nn.DataParallel(net)\n",
    "cudnn.benchmark = True \n",
    "\n",
    "learning_rate = 0.01\n",
    "file_name = 'resnet18_mnist.pt'\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0002)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "  print('\\n[ Train epoch: %d ]' % epoch)\n",
    "  net.train()\n",
    "  train_loss = 0\n",
    "  correct = 0\n",
    "  total = 0\n",
    "\n",
    "  for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    benign_outputs = net(inputs)\n",
    "    loss = criterion(benign_outputs, targets)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    train_loss += loss.item()\n",
    "    _, predicted = benign_outputs.max(1)\n",
    "\n",
    "    total += targets.size(0)\n",
    "    correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    if batch_idx % 100 == 0:\n",
    "      print('\\nCurrent batch: ', str(batch_idx))\n",
    "      print('Current benign train accuracy: ', str(predicted.eq(targets).sum().item() / targets.size(0)))\n",
    "      print('Current benign train loss: ', loss.item())\n",
    "\n",
    "  print('\\nTotal benign train accuarcy: ', 100. * correct / total)\n",
    "  print('Total benign train loss: ', train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "  print('\\n[ Test epoch: %d' % epoch)\n",
    "  net.eval()\n",
    "  loss = 0\n",
    "  correct = 0\n",
    "  total = 0\n",
    "\n",
    "  for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    total += targets.size(0)\n",
    "\n",
    "    outputs = net(inputs)\n",
    "    loss += criterion(outputs, targets).item()\n",
    "\n",
    "    _, predicted = outputs.max(1)\n",
    "    correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "  print('\\nTest accuarcy: ', 100. * correct / total)\n",
    "  print('Test average loss: ', loss / total)\n",
    "\n",
    "  state = {\n",
    "    'net': net.state_dict()\n",
    "  }\n",
    "  if not os.path.isdir('checkpoint'):\n",
    "    os.mkdir('checkpoint')\n",
    "  torch.save(state, './checkpoint/'+file_name)\n",
    "  print('Model Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "  lr = learning_rate\n",
    "  if epoch >= 5:\n",
    "    lr /= 10\n",
    "  \n",
    "  for param_group in optimizer.param_groups:\n",
    "    param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ Train epoch: 0 ]\n",
      "x: torch.Size([128, 1, 28, 28])\n",
      "out: torch.Size([128, 512])\n",
      "\n",
      "Current batch:  0\n",
      "Current benign train accuracy:  0.140625\n",
      "Current benign train loss:  2.3682894706726074\n",
      "x: torch.Size([128, 1, 28, 28])\n",
      "out: torch.Size([128, 512])\n",
      "x: torch.Size([128, 1, 28, 28])\n",
      "out: torch.Size([128, 512])\n",
      "x: torch.Size([128, 1, 28, 28])\n",
      "out: torch.Size([128, 512])\n",
      "x: torch.Size([128, 1, 28, 28])\n",
      "out: torch.Size([128, 512])\n",
      "x: torch.Size([128, 1, 28, 28])\n",
      "out: torch.Size([128, 512])\n",
      "x: torch.Size([128, 1, 28, 28])\n",
      "out: torch.Size([128, 512])\n",
      "x: torch.Size([128, 1, 28, 28])\n",
      "out: torch.Size([128, 512])\n",
      "x: torch.Size([128, 1, 28, 28])\n",
      "out: torch.Size([128, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/gyoungwon-cho/.pyenv/versions/3.9-dev/lib/python3.9/multiprocessing/queues.py\", line 251, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/gyoungwon-cho/.pyenv/versions/3.9-dev/lib/python3.9/multiprocessing/connection.py\", line 205, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/gyoungwon-cho/.pyenv/versions/3.9-dev/lib/python3.9/multiprocessing/connection.py\", line 416, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/gyoungwon-cho/.pyenv/versions/3.9-dev/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gyoungwon-cho/.pyenv/versions/3.9-dev/lib/python3.9/multiprocessing/queues.py\", line 251, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/gyoungwon-cho/.pyenv/versions/3.9-dev/lib/python3.9/multiprocessing/connection.py\", line 205, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/gyoungwon-cho/.pyenv/versions/3.9-dev/lib/python3.9/multiprocessing/connection.py\", line 416, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/gyoungwon-cho/.pyenv/versions/3.9-dev/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Users/gyoungwon-cho/.pyenv/versions/3.9-dev/lib/python3.9/multiprocessing/queues.py\", line 251, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/gyoungwon-cho/.pyenv/versions/3.9-dev/lib/python3.9/multiprocessing/connection.py\", line 205, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/gyoungwon-cho/.pyenv/versions/3.9-dev/lib/python3.9/multiprocessing/connection.py\", line 416, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/gyoungwon-cho/.pyenv/versions/3.9-dev/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/gyoungwon-cho/dev/github/pytorch-tutorial/practices/resnet/resnet18_mnist.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gyoungwon-cho/dev/github/pytorch-tutorial/practices/resnet/resnet18_mnist.ipynb#ch0000010?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m10\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gyoungwon-cho/dev/github/pytorch-tutorial/practices/resnet/resnet18_mnist.ipynb#ch0000010?line=3'>4</a>\u001b[0m   adjust_learning_rate(optimizer, epoch)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gyoungwon-cho/dev/github/pytorch-tutorial/practices/resnet/resnet18_mnist.ipynb#ch0000010?line=4'>5</a>\u001b[0m   train(epoch)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gyoungwon-cho/dev/github/pytorch-tutorial/practices/resnet/resnet18_mnist.ipynb#ch0000010?line=5'>6</a>\u001b[0m   test(epoch)\n",
      "\u001b[1;32m/Users/gyoungwon-cho/dev/github/pytorch-tutorial/practices/resnet/resnet18_mnist.ipynb Cell 11'\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gyoungwon-cho/dev/github/pytorch-tutorial/practices/resnet/resnet18_mnist.ipynb#ch0000007?line=11'>12</a>\u001b[0m benign_outputs \u001b[39m=\u001b[39m net(inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gyoungwon-cho/dev/github/pytorch-tutorial/practices/resnet/resnet18_mnist.ipynb#ch0000007?line=12'>13</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(benign_outputs, targets)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gyoungwon-cho/dev/github/pytorch-tutorial/practices/resnet/resnet18_mnist.ipynb#ch0000007?line=13'>14</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gyoungwon-cho/dev/github/pytorch-tutorial/practices/resnet/resnet18_mnist.ipynb#ch0000007?line=15'>16</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gyoungwon-cho/dev/github/pytorch-tutorial/practices/resnet/resnet18_mnist.ipynb#ch0000007?line=16'>17</a>\u001b[0m train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9-dev/envs/pytorch3.9/lib/python3.9/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/gyoungwon-cho/.pyenv/versions/3.9-dev/envs/pytorch3.9/lib/python3.9/site-packages/torch/_tensor.py?line=297'>298</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///Users/gyoungwon-cho/.pyenv/versions/3.9-dev/envs/pytorch3.9/lib/python3.9/site-packages/torch/_tensor.py?line=298'>299</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    <a href='file:///Users/gyoungwon-cho/.pyenv/versions/3.9-dev/envs/pytorch3.9/lib/python3.9/site-packages/torch/_tensor.py?line=299'>300</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    <a href='file:///Users/gyoungwon-cho/.pyenv/versions/3.9-dev/envs/pytorch3.9/lib/python3.9/site-packages/torch/_tensor.py?line=300'>301</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/gyoungwon-cho/.pyenv/versions/3.9-dev/envs/pytorch3.9/lib/python3.9/site-packages/torch/_tensor.py?line=304'>305</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    <a href='file:///Users/gyoungwon-cho/.pyenv/versions/3.9-dev/envs/pytorch3.9/lib/python3.9/site-packages/torch/_tensor.py?line=305'>306</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> <a href='file:///Users/gyoungwon-cho/.pyenv/versions/3.9-dev/envs/pytorch3.9/lib/python3.9/site-packages/torch/_tensor.py?line=306'>307</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9-dev/envs/pytorch3.9/lib/python3.9/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/gyoungwon-cho/.pyenv/versions/3.9-dev/envs/pytorch3.9/lib/python3.9/site-packages/torch/autograd/__init__.py?line=150'>151</a>\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/gyoungwon-cho/.pyenv/versions/3.9-dev/envs/pytorch3.9/lib/python3.9/site-packages/torch/autograd/__init__.py?line=151'>152</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m--> <a href='file:///Users/gyoungwon-cho/.pyenv/versions/3.9-dev/envs/pytorch3.9/lib/python3.9/site-packages/torch/autograd/__init__.py?line=153'>154</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[1;32m    <a href='file:///Users/gyoungwon-cho/.pyenv/versions/3.9-dev/envs/pytorch3.9/lib/python3.9/site-packages/torch/autograd/__init__.py?line=154'>155</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    <a href='file:///Users/gyoungwon-cho/.pyenv/versions/3.9-dev/envs/pytorch3.9/lib/python3.9/site-packages/torch/autograd/__init__.py?line=155'>156</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 학습 진행\n",
    "# MNIST 데이터셋에 대하여 전체 10 epoch로 99.5% test accuracy를 시연할 수 있습니다.\n",
    "for epoch in range(0, 10):\n",
    "  adjust_learning_rate(optimizer, epoch)\n",
    "  train(epoch)\n",
    "  test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "819822aad1d7dd5a8911f6442f86af1dcc8bcd014a1dc82c30af569169ee7dac"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('pytorch3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
