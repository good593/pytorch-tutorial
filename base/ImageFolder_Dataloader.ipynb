{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://mjdeeplearning.tistory.com/97\n",
    "- https://hayunjong83.tistory.com/47\n",
    "\n",
    "### ImageFolder\n",
    "torchvision.datasets.ImageFolder를 호출하면 갖춰진 데이터 폴더 구조로부터 PyTorch dataset을 만들어준다.  \n",
    "> 내부적으로 샘플에 대한 인덱싱을 제공하고, 문자열로 된 클래스명들을 0번 클래스, 1번 클래스와 같이 정수 인덱스로 바꿔주는 작업이 이뤄지지만, 이런 복잡한 내부 작업을 숨기고 간단한 메소드 호출만으로 작업이 이뤄지게 하는 것이 라이브러리의 힘이다.  \n",
    "  \n",
    "ImageFolder 메소드는 ants/bees가 속한 train 폴더로부터 train dataset을, ants/bees가 속한 val 폴더로부터 validation dataset을 자동으로 만들어줄 것이다.  \n",
    "PyTorch dataset을 만들면서 torchvision 라이브러리를 쓰는 방식의 장점은 이미지 변형(Image transformation)을 손쉽게 할 수 있다는 점이다. \n",
    "### Transforms\n",
    "torchvision.transforms을 이용해서 변형 방식을 구성한 다음에 dataset을 만들 때 넘겨주는 것으로 충분하다.  \n",
    "- transforms.Compose: 여러 변형 방식을 한꺼번에 묶어준다.\n",
    "- transforms.RandomResizedCrop: 원본 이미지를 지정된 스케일 범위와 지정된 비율로 무작위로 자른 후에, 지정된 크기로 리사이즈 한다. \n",
    "- transforms.Resize: 입력 이미지를 주어진 크기로 리사이즈한다.\n",
    "- transforms.CenterCrop: 입력 이미지의 중앙에서 시작하여 주어진 크기만큼 크롭한다. 참고로 입력 이미지 크기가 출력하려는 크기보다 작으면 부족한 부분의 픽셀값들이 0으로 패딩, 즉 채워진 다음에 크롭된다.\n",
    "- transforms.HorizontalFlip: 주어진 확률로 이미지를 수평반전 시킨다. 여기서는 확률값을 지정하지 않았으므로 디폴트 값인 0.5의 확률로 이미지들이 수평반전 된다. 즉, 훈련 이미지 중 절반은 그대로지만, 절반은 뒤집히게 될 것이다.\n",
    "- transforms.ToTensor: 사전훈련된 모델 사용과 효율적 연산을 위해서 torch.FloatTensor 배열로 바꿔줘야 한다. \n",
    "> 이 때, 픽셀값의 범위가 [0.0, 1.0] 사이가 되도록 바꿔줘야하며 차원의 순서를 바꿔서 (채널수, 높이, 너비)가 되게 해야한다. 이 작업을 수행해주는 메소드이다.\n",
    "- transforms.Normalize: transfer learning에서 사용하는 pretrain model들은 대게 ImageNet 데이터셋에서 사전훈련되어있다. 이 모델을 사용하기 위해서 ImageNet 데이터의 각 채널별 평균과 표준편차를 이용해 정규화해준다. \n",
    "> OpenCV를 사용해 이미지를 읽어온다면 RGB이미지가 아닌 BGR이미지이므로, 채널 순서를 염두에 둬야 할 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim \n",
    "\n",
    "import torchvision \n",
    "from torchvision import datasets, models, transforms \n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = {\n",
    "  'train': transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "  ]),\n",
    "  'val': transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "  ])\n",
    "}\n",
    "\n",
    "data_dir = '../data/hymenoptera_data'\n",
    "image_datasets = {\n",
    "  x: datasets.ImageFolder(os.path.join(data_dir, x), data_transform[x]) for x in ['train', 'val']\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "  x: DataLoader(\n",
    "    image_datasets[x], batch_size=4, shuffle=True, num_workers=4\n",
    "  ) for x in ['train', 'val']\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "  x: len(image_datasets[x]) for x in ['train', 'val']\n",
    "}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ants', 'bees']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 244, 'val': 153}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "819822aad1d7dd5a8911f6442f86af1dcc8bcd014a1dc82c30af569169ee7dac"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('pytorch3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
