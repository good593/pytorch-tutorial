{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [텐서](https://tutorials.pytorch.kr/beginner/basics/tensorqs_tutorial.html)\n",
    "- https://subinium.github.io/pytorch-Tensor-Variable/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[1, 2],[3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 2],\n",
       "        [3, 4]]),\n",
       " tensor([[1, 2],\n",
       "         [3, 4]], dtype=torch.int32))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "np_array, x_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.3421, 0.2420],\n",
      "        [0.3782, 0.5077]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data) # x_data의 속성을 유지합니다.\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # x_data의 속성을 덮어씁니다.\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.9897, 0.7628, 0.2327],\n",
      "        [0.7702, 0.7828, 0.8800]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.1392, 0.2380, 0.1032, 0.6953],\n",
      "        [0.7158, 0.3913, 0.0911, 0.1545],\n",
      "        [0.2038, 0.0664, 0.9982, 0.2105]]) \n",
      "\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f\"Random Tensor: \\n {tensor} \\n\")\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cuda 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU가 존재하면 텐서를 이동합니다\n",
    "if torch.cuda.is_available():\n",
    "  tensor = tensor.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor 차원 재구성\n",
    "- reshape(), view()\n",
    "> 둘 모두 문법은 동일합니다. x.view(1,2,3), x.reshape(1,2,3)처럼 변경하고 싶은 shape을 tuple로 입력으로 주면 됩니다.  \n",
    "> 여기서는 정말 미세한 차이가 있습니다. \n",
    "> - `view`는 기존의 데이터와 같은 메모리 공간을 공유하며 stride 크기만 변경하여 보여주기만 다르게 합니다. 그래서 contiguous 해야만 동작하며, 아닌 경우 에러가 발생합니다.  \n",
    "> - `reshape`는 메머리가 기존 Tensor와 동일한 메모리를 공유하는게 보장되지만 reshape은 그렇지 않습니다. \n",
    "> - 안전하게 형태만 바꾸고 싶다 -> reshape\n",
    "> - 메모리가 공유되어 업데이트에 대한 보장이 이뤄진다 -> view  \n",
    "  \n",
    "- transpose(), permute()\n",
    "> 종종 channel 차원을 마지막으로 보내야하는 순간이 존재하고, 연산에 따라 차원 간의 순서를 변경해줄 필요가 있습니다.  \n",
    "> - `transpose()`: 2개의 차원을 변경하는데 사용\n",
    "> - `permute()`: 모든 차원의 순서를 재배치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
      "v: tensor([[[ 0,  1],\n",
      "         [ 2,  3]],\n",
      "\n",
      "        [[ 4,  5],\n",
      "         [ 6,  7]],\n",
      "\n",
      "        [[ 8,  9],\n",
      "         [10, 11]]])\n",
      "r: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
      "t: tensor([[[ 0,  4,  8],\n",
      "         [ 1,  5,  9]],\n",
      "\n",
      "        [[ 2,  6, 10],\n",
      "         [ 3,  7, 11]]])\n"
     ]
    }
   ],
   "source": [
    "x =torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n",
    "print(f'x: {x}')\n",
    "\n",
    "# view, reshape\n",
    "v = x.view(3,2,2)\n",
    "print(f'v: {v}')\n",
    "r = v.reshape(-1)\n",
    "print(f'r: {r}')\n",
    "\n",
    "# transpose, permute\n",
    "t = v.permute(1,2,0)\n",
    "print(f't: {t}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft: torch.Size([4, 4, 3])\n",
      "v1: torch.Size([16, 3])\n",
      "v2: torch.Size([8, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "t = np.zeros((4, 4, 3))\n",
    "ft = torch.FloatTensor(t)\n",
    "print(f'ft: {ft.shape}')\n",
    "v1 = ft.view([-1, 3]) # ft라는 텐서를(?, 3)의 크기로 변경\n",
    "print(f'v1: {v1.shape}')\n",
    "v2 = ft.view([-1, 2, 3]) # ft라는 텐서를 (?, 2, 3)의 크기로 변경\n",
    "print(f'v2: {v2.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 더미 차원 추가와 삭제: squeeze(), unsqueeze()\n",
    "`Tensor`는 결국 모델에 넣기 위한 data의 변형이며 data에 따라 Tensor의 차원도 달라집니다. 보통 모델에 넣는 데이터의 shape은 다음과 같습니다.\n",
    "- signal data `N, C, L`: batch, channel, length\n",
    "- image data `N, C, H, W`: batch, channel, height, weight  \n",
    "  \n",
    "하지만 inference시 batchsize가 1이 되어 shape이 안맞는 경우, 아니면 후에 Conv연산을 위해 가상 channel이 필요한 경우, tensor간 연산을 위해 channel을 추가해야하는 경우 등등 size가 1인 차원을 추가하거나 없애야하는 상황이 많습니다.  \n",
    "- squeeze(): 차원의 size가 1인 차원을 없애줌\n",
    "  - 여러개의 차원 중 특정 차원만 지우고 싶다면, x.squeesz(1)처럼 사용, 아니면 모두 제거\n",
    "- unsqueeze(): 차원 size가 1인 차원을 생성\n",
    "  - idx번째 차원을 만들면 기존 idx차원부터 한칸씩 미뤄짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.2538, 0.8653, 0.8758, 0.4422],\n",
      "        [0.1578, 0.2791, 0.3726, 0.8337],\n",
      "        [0.8387, 0.5881, 0.9932, 0.2651],\n",
      "        [0.8919, 0.9574, 0.8619, 0.8216]]) \n",
      "\n",
      "First row:  tensor([0.2538, 0.8653, 0.8758, 0.4422])\n",
      "First column:  tensor([0.2538, 0.1578, 0.8387, 0.8919])\n",
      "Last column: tensor([0.4422, 0.8337, 0.2651, 0.8216])\n",
      "Last column: tensor([0.4422, 0.8337, 0.2651, 0.8216])\n",
      "tensor([[0.2538, 0.0000, 0.8758, 0.4422],\n",
      "        [0.1578, 0.0000, 0.3726, 0.8337],\n",
      "        [0.8387, 0.0000, 0.9932, 0.2651],\n",
      "        [0.8919, 0.0000, 0.8619, 0.8216]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(4, 4)\n",
    "\n",
    "print(f\"Random Tensor: \\n {tensor} \\n\")\n",
    "print('First row: ',tensor[0])\n",
    "print('First column: ', tensor[:, 0])\n",
    "print('Last column:', tensor[:, -1])\n",
    "print('Last column:', tensor[..., -1])\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2538, 0.0000, 0.8758, 0.4422, 0.2538, 0.0000, 0.8758, 0.4422, 0.2538,\n",
      "         0.0000, 0.8758, 0.4422],\n",
      "        [0.1578, 0.0000, 0.3726, 0.8337, 0.1578, 0.0000, 0.3726, 0.8337, 0.1578,\n",
      "         0.0000, 0.3726, 0.8337],\n",
      "        [0.8387, 0.0000, 0.9932, 0.2651, 0.8387, 0.0000, 0.9932, 0.2651, 0.8387,\n",
      "         0.0000, 0.9932, 0.2651],\n",
      "        [0.8919, 0.0000, 0.8619, 0.8216, 0.8919, 0.0000, 0.8619, 0.8216, 0.8919,\n",
      "         0.0000, 0.8619, 0.8216]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2538, 0.0000, 0.8758, 0.4422],\n",
      "        [0.1578, 0.0000, 0.3726, 0.8337],\n",
      "        [0.8387, 0.0000, 0.9932, 0.2651],\n",
      "        [0.8919, 0.0000, 0.8619, 0.8216],\n",
      "        [0.2538, 0.0000, 0.8758, 0.4422],\n",
      "        [0.1578, 0.0000, 0.3726, 0.8337],\n",
      "        [0.8387, 0.0000, 0.9932, 0.2651],\n",
      "        [0.8919, 0.0000, 0.8619, 0.8216],\n",
      "        [0.2538, 0.0000, 0.8758, 0.4422],\n",
      "        [0.1578, 0.0000, 0.3726, 0.8337],\n",
      "        [0.8387, 0.0000, 0.9932, 0.2651],\n",
      "        [0.8919, 0.0000, 0.8619, 0.8216]])\n"
     ]
    }
   ],
   "source": [
    "t2 = torch.cat([tensor, tensor, tensor], dim=0)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2538, 0.1578, 0.8387, 0.8919, 0.2538, 0.1578, 0.8387, 0.8919, 0.2538,\n",
       "        0.1578, 0.8387, 0.8919])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0270, 0.7351, 1.2000, 1.3445],\n",
       "        [0.7351, 0.8588, 0.7235, 1.1468],\n",
       "        [1.2000, 0.7235, 1.7601, 1.8218],\n",
       "        [1.3445, 1.1468, 1.8218, 2.2132]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 두 텐서 간의 행렬 곱(matrix multiplication)을 계산합니다. y1, y2, y3은 모두 같은 값을 갖습니다.\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(tensor)\n",
    "torch.matmul(tensor, tensor.T, out=y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0644, 0.0000, 0.7670, 0.1956],\n",
       "        [0.0249, 0.0000, 0.1389, 0.6951],\n",
       "        [0.7033, 0.0000, 0.9864, 0.0703],\n",
       "        [0.7954, 0.0000, 0.7428, 0.6749]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 요소별 곱(element-wise product)을 계산합니다. z1, z2, z3는 모두 같은 값을 갖습니다.\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.608250617980957 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2538, 0.0000, 0.8758, 0.4422],\n",
      "        [0.1578, 0.0000, 0.3726, 0.8337],\n",
      "        [0.8387, 0.0000, 0.9932, 0.2651],\n",
      "        [0.8919, 0.0000, 0.8619, 0.8216]]) \n",
      "\n",
      "tensor([[5.2538, 5.0000, 5.8758, 5.4422],\n",
      "        [5.1578, 5.0000, 5.3726, 5.8337],\n",
      "        [5.8387, 5.0000, 5.9932, 5.2651],\n",
      "        [5.8919, 5.0000, 5.8619, 5.8216]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor, \"\\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2624e9e26dc28606847f9c891d4a6e50802c9dcfadd8d870a86289f610452f5a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
